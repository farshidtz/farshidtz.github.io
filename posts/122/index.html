<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Smartphone Position Detection Using Neural Networks - Farshid Tavakolizadeh</title><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:image" content><meta property="og:title" content="Smartphone Position Detection Using Neural Networks"><meta property="og:description" content="This application is developed in C++ using the well known OpenCV Library. The application demo and the list of all features are available below:
Control Features with camera:
 Changing the brush color Changing the brush thickness Clearing the screen Saving the image Closing the application  Noise Handing:
 Setting threshold for the maximum distance between two points Getting use of the pointer&rsquo;s area to distinguish between the pointer itself and noises Using a 5x5 Median Filter to reduce the background noiseThis project demonstrates an approach to detect common smart phone positions, including “In Hand”, “Side Pocket”, “In Handbag”, and “On Table (Idle)”."><meta property="og:type" content="article"><meta property="og:url" content="https://home.farshid.ws/posts/122/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2015-10-16T00:00:00+00:00"><meta property="article:modified_time" content="2015-10-16T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Smartphone Position Detection Using Neural Networks"><meta name=twitter:description content="This application is developed in C++ using the well known OpenCV Library. The application demo and the list of all features are available below:
Control Features with camera:
 Changing the brush color Changing the brush thickness Clearing the screen Saving the image Closing the application  Noise Handing:
 Setting threshold for the maximum distance between two points Getting use of the pointer&rsquo;s area to distinguish between the pointer itself and noises Using a 5x5 Median Filter to reduce the background noiseThis project demonstrates an approach to detect common smart phone positions, including “In Hand”, “Side Pocket”, “In Handbag”, and “On Table (Idle)”."><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel=stylesheet><link href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://home.farshid.ws/css/main.css><link rel=stylesheet type=text/css href=https://home.farshid.ws/css/dark.css media="(prefers-color-scheme: dark)"></head><body><div class=content><header><div class=main><a href=https://home.farshid.ws/>Farshid Tavakolizadeh</a></div><nav></nav></header><main><article><div class=title><h1 class=title>Smartphone Position Detection Using Neural Networks</h1><div class=meta>Posted on Oct 16, 2015</div></div><section class=body><p>This application is developed in C++ using the well known OpenCV Library. The application demo and the list of all features are available below:</p><p><strong>Control Features with camera:</strong></p><ul><li>Changing the brush color</li><li>Changing the brush thickness</li><li>Clearing the screen</li><li>Saving the image</li><li>Closing the application</li></ul><p><strong>Noise Handing:</strong></p><ul><li>Setting threshold for the maximum distance between two points</li><li>Getting use of the pointer&rsquo;s area to distinguish between the pointer itself and noises</li><li>Using a 5x5 Median Filter to reduce the background noiseThis project demonstrates an approach to detect common smart phone positions, including “In Hand”, “Side Pocket”, “In Handbag”, and “On Table (Idle)”. We apply sensor data fusion on a set of hardware- and software-based Android sensors. As a result, data entries containing sensor fusion features are classified individually, without looking at patterns. The overall system design and accuracy are presented using a Google Nexus 6 device.</li></ul><center><figure><img src=network.png width=80%><figcaption><h4>The fully connected NN used for classification. Nodes: 13 - 8 - 8 - 4</h4></figcaption></figure><figure><img src=prediction.png width=80%><figcaption><h4>Prediction system diagram. Remote prediction using Weka.</h4></figcaption></figure><figure><img src=android-app-logging.jpg width=40%><figcaption><h4>Android Application: Logging mode</h4></figcaption></figure><figure><img src=android-app-prediction.jpg width=40%><figcaption><h4>Android Application: Prediction mode</h4></figcaption></figure></center><p><a href=https://github.com/farshidtz/mss2015>Source Codes</a> | <a href=slides.pdf>Slides</a></p></section><div class=post-tags></div></article></main><footer><hr><a class=soc href=https://github.com/farshidtz title=GitHub><i data-feather=github></i></a>|<a class=soc href=https://linkedin.com/in/farshidt title=LinkedIn><i data-feather=linkedin></i></a>|<a class=soc href="https://scholar.google.com/citations?user=RULta1sAAAAJ&hl=en" title="Google Scholar"><i data-feather=book-open></i></a>|⚡️
2021 © Farshid Tavakolizadeh | <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></footer><script>feather.replace()</script></div></body></html>